name: 'Triage AI Action'
description: 'Run AI inference.'

inputs:
  token:
    description: 'GitHub token to use for authentication'
    required: false
    default: ${{ github.token }}
  prompt-file:
    description: 'Path to the user prompt file'
    required: true
  system-prompt-file:
    description: 'Path to the system prompt file'
    required: false
  response-file:
    description: 'Path to the file where the AI response will be saved'
    required: true
  model:
    description: The model to use
    required: false
    default: 'openai/gpt-4o'
  endpoint:
    description: The endpoint to use
    required: false
    default: 'https://models.github.ai/inference'
  max-tokens:
    description: 'Maximum number of tokens for the AI response'
    required: false
    default: '200'

outputs:
  response:
    description: 'The file that contains the AI response'
    value: ${{ steps.move-response.outputs.response }}

runs:
  using: 'composite'
  steps:

    - name: Run AI inference
      id: inference
      uses: actions/ai-inference@main
      with:
        model: ${{ inputs.model }}
        endpoint: ${{ inputs.endpoint }}
        max-tokens: ${{ inputs.max-tokens }}
        prompt-file: ${{ inputs.prompt-file }}
        system-prompt-file: ${{ inputs.system-prompt-file }}

    - name: Move AI response to response file
      id: move-response
      shell: pwsh
      run: |
        "Move AI response to response file"
        echo "::group::Move AI response to response file"
        $src = "${{ steps.inference.outputs.response-file }}"
        $dst = "${{ inputs.response-file }}"
        Move-Item -Path $src -Destination $dst -Force
        Add-Content -Path $dst -Value "`n"
        "response=$dst" >> $env:GITHUB_OUTPUT
        echo "::endgroup::"

    - name: Print AI response
      shell: pwsh
      run: |
        "Print AI response"
        echo "::group::AI Response"
        cat "${{ steps.move-response.outputs.response }}"
        echo "::endgroup::"
