---
description: "Comprehensive guide for working with the .NET MAUI Sandbox app for testing, validation, and experimentation"
applyTo: "src/Controls/samples/Controls.Sample.Sandbox/**"
---

# Sandbox Testing Guide

Comprehensive guide for working with the .NET MAUI Sandbox app for manual testing, PR validation, issue reproduction, and experimentation with MAUI features.

## When This Applies

This guide applies when you:
- Work with files in `src/Controls/samples/Controls.Sample.Sandbox/`
- User asks to "test this PR" or "validate PR #XXXXX" in Sandbox
- User asks to "reproduce issue #XXXXX" in Sandbox
- User wants to deploy to iOS/Android for manual testing
- User mentions Sandbox app by name in testing context

## ğŸš¨ CRITICAL VALIDATION RULES - READ FIRST

**YOU MUST FOLLOW THESE RULES WHEN RUNNING SANDBOX TESTS:**

### What You NEVER Do (Absolute Rules)

- âŒ **NEVER** assume test completion without validation
- âŒ **NEVER** claim success based on HTTP 200 responses alone (element found â‰  test completed)
- âŒ **NEVER** skip the mandatory validation checklist
- âŒ **NEVER** proceed without verifying device logs show expected behavior
- âŒ **NEVER** assume Appium connection means test finished
- âŒ **NEVER** claim button was tapped without checking device logs

### What You ALWAYS Do (Mandatory Steps)

- âœ… **ALWAYS** save full output to file for analysis
- âœ… **ALWAYS** check for errors/exceptions FIRST before claiming success
- âœ… **ALWAYS** verify "Test completed" marker appears in output
- âœ… **ALWAYS** verify expected test actions in logs (Tapping, Screenshot, etc.)
- âœ… **ALWAYS** check device logs for Console.WriteLine markers
- âœ… **ALWAYS** verify artifacts exist (screenshots, if test captures them)

### Rule 1: NEVER ASSUME TEST COMPLETION
- âŒ **DO NOT** assume the test completed successfully just because Appium connected
- âŒ **DO NOT** assume success based on HTTP 200 responses (element found â‰  test completed)
- âœ… **DO** verify test completion by checking for completion markers in output
- âœ… **DO** search for "Test completed", "â•â•â•â•â•â•â•", or final summary messages

### Rule 2: ALWAYS VALIDATE TEST OUTPUT
After running BuildAndRunSandbox.ps1, you MUST:
1. **Save full output to file**: `pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform ios > CustomAgentLogsTmp/Sandbox/build-run-output.log 2>&1`
2. **Check for errors FIRST**: `grep -E "ERROR|Exception|failed" CustomAgentLogsTmp/Sandbox/build-run-output.log`
3. **Verify completion markers**: `grep "Test completed\|â•â•â•â•â•â•" CustomAgentLogsTmp/Sandbox/build-run-output.log`
4. **Check for expected actions**: `grep "Tapping\|Screenshot saved\|switched to" CustomAgentLogsTmp/Sandbox/build-run-output.log`

### Rule 3: VALIDATE DEVICE LOGS FOR EXPECTED BEHAVIOR
- âœ… **DO** check device logs confirm your expected test actions happened
- âœ… **DO** grep for your Console.WriteLine markers (e.g., "SANDBOX.*CLICKED")
- âŒ **DO NOT** claim the test worked without verifying device logs show the action

### Rule 4: SYSTEMATIC VALIDATION CHECKLIST
After EVERY test run, verify ALL of these **IN THIS ORDER**:

```bash
# Step 1: Check for errors/exceptions FIRST
grep -iE "error|exception|failed" CustomAgentLogsTmp/Sandbox/build-run-output.log | grep -v "no such element" | head -20

# Step 2: Verify expected test actions (MOST IMPORTANT - proves test actually ran)
grep -E "Tapping|Screenshot saved|Found.*element|Clicking|Entering text" CustomAgentLogsTmp/Sandbox/build-run-output.log

# Step 3: Verify test completion marker
grep "Test completed" CustomAgentLogsTmp/Sandbox/build-run-output.log

# Step 4: Verify device logs show expected behavior
grep "SANDBOX" CustomAgentLogsTmp/Sandbox/android-device.log  # or ios-device.log

# Step 5: Check screenshots were saved (if test captures them)
ls -lh CustomAgentLogsTmp/Sandbox/*.png

# Step 6: Check exit code
echo $?  # Should be 0 for success
```

**CRITICAL**: If Step 2 shows NO test actions, the test didn't actually run even if it "completed successfully". Update your Appium test and rerun.

**If ANY of these checks fail, the test DID NOT complete successfully. Investigate and fix before proceeding.**

---

## ğŸš¨ WARNING: "Test Completed Successfully" â‰  Test Actually Worked

**CRITICAL UNDERSTANDING**: The message "âœ… Test completed successfully" only means:
- âœ… Appium test script finished running without crashing
- âœ… Script exit code was 0

**It does NOT mean**:
- âŒ Appium found your UI elements
- âŒ Buttons were clicked
- âŒ Navigation happened
- âŒ Your test scenario actually ran

### Example of False Success

**What you see in output**:
```
âœ… Test completed successfully

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Test Summary                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Platform:     ANDROID                                    â•‘
â•‘  Device:       emulator-5554                              â•‘
â•‘  Result:       SUCCESS âœ…                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**What actually happened**:
```bash
# Check the logs:
grep "no such element" CustomAgentLogsTmp/Sandbox/build-run-output.log
# Result: 20+ lines of "no such element" errors

# The test looked for "InstructionLabel" which doesn't exist in MainPage
# Appium never found ANY elements
# Test script just gave up and exited with code 0
# NO ACTUAL TESTING WAS PERFORMED
```

### How to Detect False Success

**MANDATORY check after EVERY "successful" test**:
```bash
# Look for actual test actions in output
grep -E "Tapping|Clicking|Found element|Screenshot saved" CustomAgentLogsTmp/Sandbox/build-run-output.log
```

**If grep returns NOTHING â†’ FALSE SUCCESS**:
- Test didn't actually do anything
- Template test is looking for elements that don't exist
- You MUST update `CustomAgentLogsTmp/Sandbox/RunWithAppiumTest.cs` to match your MainPage
- Rerun BuildAndRunSandbox.ps1 after updating test

**If grep returns multiple lines â†’ REAL SUCCESS**:
- Test found elements and interacted with them
- Proceed with full validation checklist

---

## Purpose

Work with the Sandbox app for manual testing, PR validation, issue reproduction, and experimentation with MAUI features.

## When to Use Sandbox Testing

- âœ… User asks to "test this PR" (functional testing, not code review)
- âœ… User asks to "validate PR #XXXXX" or "validate PR #XXXXX in Sandbox"
- âœ… User asks to "reproduce issue #XXXXX" or "try out issue #XXXXX"
- âœ… User asks to "try out" or "experiment with" a feature in Sandbox
- âœ… PR modifies core MAUI functionality (controls, layouts, platform code)
- âœ… Need to manually verify a fix works on device/simulator
- âœ… Need to create a quick test scenario for hands-on validation

## When NOT to Use Sandbox

- âŒ User asks to "review PR #XXXXX" â†’ Use **pr-reviewer** agent for code review
- âŒ User asks to "write UI tests" or "create automated tests" â†’ Use **uitest-coding-agent**
- âŒ User asks to "validate the UI tests" or "verify test quality" â†’ Review test code instead
- âŒ User asks to "fix issue #XXXXX" â†’ Use **issue-resolver** agent
- âŒ PR only adds documentation (no code changes to test)
- âŒ PR only modifies build scripts (no functional changes)

## Distinction: Code Review vs. Functional Testing

**Code Review** (pr-reviewer agent):
- Analyzes code quality, patterns, best practices
- Reviews test coverage and correctness
- Checks for potential bugs or issues in the code itself
- Trigger: "review PR", "review pull request", "code review"

**Functional Testing** (sandbox-agent):
- Builds and deploys PR to device/simulator
- Manually validates the fix works as expected
- Reproduces issues and verifies they're resolved
- Trigger: "test this PR", "validate PR in Sandbox", "reproduce issue"

## ğŸš¨ Critical Requirements for Android Testing

**ANDROID-ONLY REQUIREMENT - appium:noReset**

âš ï¸ **This ONLY applies to Android, NOT iOS**

When testing on Android, the Appium test script **MUST** have this capability:

```csharp
// ANDROID ONLY - Do NOT add this for iOS
if (PLATFORM == "android")
{
    options.AddAdditionalAppiumOption("appium:noReset", true);
}
```

**Why this is critical for Android:**
- Without `noReset`, Appium clears app data between runs
- This breaks .NET MAUI's Fast Deployment mechanism on Android
- App crashes with: `"No assemblies found in '.../__override__/...' ... Assuming this is part of Fast Deployment. Exiting..."`
- The app will crash immediately on launch before any test can run

**iOS does NOT need this** - iOS deployment works differently and doesn't use Fast Deployment

**Where to set it:**
- Template: `.github/scripts/templates/RunWithAppiumTest.template.cs` (line ~68, Android section only)
- Active test: `CustomAgentLogsTmp/Sandbox/RunWithAppiumTest.cs` (Android section only)

**Platform detection is automatic** - The template automatically detects Android vs iOS from the UDID format, so you don't need to manually set the platform. The `if (PLATFORM == "android")` block will execute automatically when testing on Android.

**âš ï¸ NEVER REMOVE THIS CAPABILITY FROM ANDROID** - All Android tests depend on it

---

## Core Workflow

**ğŸš¨ CRITICAL RULE FOR ENTIRE WORKFLOW:**
- **ALWAYS use BuildAndRunSandbox.ps1 script** for building, deploying, and testing
- **NEVER use manual `dotnet build`, `adb`, or `xcrun` commands**
- The script handles device detection, build, deployment, and test execution automatically
- See "BuildAndRunSandbox.ps1 Script" section below for full details

---

### Step 1: Checkout PR and Understand Issue

```bash
# Fetch and checkout PR
gh pr checkout <PR_NUMBER>
```

**Understand the issue thoroughly:**
- Read PR description and linked issue report
- Identify what bug is being fixed
- Note affected platforms
- Look for reproduction steps in the issue
- Review PR changes to understand the fix

---

### Step 2: Create Test Scenario in Sandbox

**Choose test scenario source (in priority order):**

1. **From Issue Reproduction** (Preferred)
   - Look for "Reproduction" or "Steps to Reproduce" in the linked issue
   - Use the exact scenario the user reported
   - This proves you're testing what the user experienced

2. **From PR's UI Tests** (Alternative)
   - Check if PR includes files in `TestCases.HostApp/Issues/IssueXXXXX.*`
   - Adapt the test page code to Sandbox
   - Simplify if needed for manual testing

3. **Create Your Own** (Last Resort)
   - If no repro available, design scenario based on PR changes
   - Focus on the specific code paths modified by the fix
   - Keep it simple and focused

**Files to modify**:
- `src/Controls/samples/Controls.Sample.Sandbox/MainPage.xaml[.cs]` - UI and code for reproduction
- `CustomAgentLogsTmp/Sandbox/RunWithAppiumTest.cs` - Appium test script (MANDATORY - see setup below)

**Setting up the Appium test file (MANDATORY):**

ğŸš¨ **CRITICAL**: Update Appium test BEFORE running script. Template will give FALSE SUCCESS otherwise.

1. **Create test file**:
   ```bash
   mkdir -p CustomAgentLogsTmp/Sandbox
   cp .github/scripts/templates/RunWithAppiumTest.template.cs CustomAgentLogsTmp/Sandbox/RunWithAppiumTest.cs
   ```

2. **Update test to match MainPage**:
   - Check AutomationIds: `grep AutomationId MainPage.xaml`
   - Update test to use those IDs (not template defaults)
   - Add test logic: tap buttons, verify labels
   - Add `Console.WriteLine("SANDBOX ...")` markers

3. **Example**:
   ```bash
   # Check MainPage
   grep 'AutomationId=' MainPage.xaml
   # Update test: App.WaitForElement("NavigateButton");
   ```

**Checklist**:
- âœ… Add AutomationIds to MainPage.xaml elements
- âœ… Update RunWithAppiumTest.cs to match
- âœ… Add SANDBOX markers for debugging

**ğŸš¨ CRITICAL - Document Your Test Scenario:**

You MUST include in your final report:
- âœ… **Source**: Where did the test scenario come from? (issue reproduction / PR UITest / custom)
- âœ… **Why**: Why did you choose that source? (e.g., "Issue #XXXXX provides detailed repro steps")
- âœ… **What**: What specific actions does your test perform? (e.g., "Tap button â†’ verify label changes to 'Success'")
- âœ… **Expected**: What behavior should occur? (from issue description or PR changes)

Without this documentation, user cannot verify you tested the right thing.

---

### Step 3: Test WITH PR Fix

**Platform Selection Decision Tree:**

Follow this flowchart in order - stop at the first match:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Does PR title have platform tag? [Android], [iOS], etc.     â”‚
â”‚    YES â†’ Test that platform ONLY                                â”‚
â”‚    NO  â†’ Continue to step 2                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Are ALL modified files in platform-specific paths?          â”‚
â”‚    (Platform/Android/, Platform/iOS/, *.Android.cs, etc.)      â”‚
â”‚    YES â†’ Test that platform ONLY                                â”‚
â”‚    NO  â†’ Continue to step 3                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Does issue report mention a specific platform?              â”‚
â”‚    YES (one platform)  â†’ Test that platform ONLY               â”‚
â”‚    YES (multiple)      â†’ Test Android + iOS                    â”‚
â”‚    NO  â†’ Continue to step 4                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Is this high-risk cross-platform code?                      â”‚
â”‚    (Controls/, Core/, layout, navigation, critical controls)   â”‚
â”‚    YES â†’ Test Android + iOS                                     â”‚
â”‚    NO  â†’ Test Android ONLY (default - faster)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Platform-specific path indicators:**
- `Platform/Android/` or `Platform/iOS/` â†’ Platform-specific
- Files with `.Android.`, `.iOS.`, `.MacCatalyst.` in name â†’ Platform-specific
- `Controls/`, `Core/` without platform subfolders â†’ Cross-platform

**Hard rule:** Never test more than 2 platforms unless user explicitly requests it.

**Run Test on Specific iOS Device/Version:**

When user requests a specific iOS version or device:

1. **Find the UDID for that device/version combination**:
   ```bash
   # Example: Find iPhone Xs with iOS 18.5
   UDID=$(xcrun simctl list devices available --json | jq -r '
     .devices 
     | to_entries 
     | map(select(.key | contains("iOS-18-5"))) 
     | map(.value) 
     | flatten 
     | map(select(.name == "iPhone Xs")) 
     | first 
     | .udid
   ')
   
   echo "Found UDID: $UDID"
   ```

2. **Pass the UDID to the script**:
   ```bash
   pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform ios -DeviceUdid "$UDID"
   ```

**Examples:**
- **"Run on iOS 18.5"** â†’ Find iPhone Xs with iOS 18.5, get UDID, pass to script
- **"Run on iPhone 15"** â†’ Find iPhone 15 (any iOS), get UDID, pass to script
- **"Run on iPhone 16 Pro with iOS 18.0"** â†’ Find iPhone 16 Pro with iOS 18.0, get UDID, pass to script

---

## How the Template Works

**The template ALWAYS does the same thing:**

1. âœ… Verifies app launched successfully (WaitForElement)
2. âœ… Optionally runs automated UI tests (if you add them)
3. âœ… Exits WITHOUT closing the app (stays running for manual validation)

**Usage:**
```bash
# Copy the template
cp .github/scripts/templates/RunWithAppiumTest.template.cs CustomAgentLogsTmp/Sandbox/RunWithAppiumTest.cs

# OPTIONAL: Add automated test logic in the TEST LOGIC section
# If you don't add test logic, it just verifies launch and exits

# Run the script
pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform ios
```

**Result:**
- App launches and stays running
- You can manually validate in the simulator
- Test script exits without closing the app

---

## ğŸš¨ CRITICAL: BuildAndRunSandbox.ps1 Script - ONLY Way to Deploy Sandbox

**YOU MUST ALWAYS USE THIS SCRIPT. NEVER USE MANUAL `dotnet build`, `adb`, or `xcrun` COMMANDS.**

### Script Location
`.github/scripts/BuildAndRunSandbox.ps1`

### Basic Usage
```powershell
# Android
pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform Android

# iOS (auto-detects device)
pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform iOS

# iOS with specific device
pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform iOS -DeviceUdid "YOUR-DEVICE-UDID"
```

### What the Script Does Automatically
- âœ… **Device detection and boot** - Finds and boots simulator/emulator
- âœ… **UDID extraction** - Sets DEVICE_UDID environment variable
- âœ… **Fresh app build** - Builds Sandbox project for target platform
- âœ… **App deployment** - Installs and launches app
- âœ… **Appium server management** - Starts/stops Appium automatically
- âœ… **Log capture** - Saves device and Appium logs to `CustomAgentLogsTmp/Sandbox/`
- âœ… **Test execution** - Runs your Appium test script

### Requirements Before Running
Copy and update test file (see Step 2 above). Template looks for "InstructionLabel" which doesn't exist - update first!

**ğŸš¨ POST-TEST VALIDATION (MANDATORY):**

After script completes, run Rule 4 validation checklist (see above). If ANY check fails: investigate, fix, rerun.

**Key reminders**:
- HTTP 200 = element found, NOT test completed
- If no test actions in logs = FALSE SUCCESS
- If Appium can't find initial element = app crashed or AutomationIds wrong

---

### ğŸ“ Note for User

**Test scenario is ready in Sandbox for manual verification.**

**To verify bug reproduction (optional):**
```bash
# 1. Revert the PR fix files
git checkout main -- [list specific fix files from PR]

# 2. Rerun test - bug should appear
pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform [android|ios]

# 3. Restore fix
git checkout HEAD -- [fix files]

# 4. Rerun test - bug should be gone
pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform [android|ios]
```

This proves the test scenario correctly reproduces the bug.

---

## ğŸ”„ Iterative Testing Workflow (MANDATORY PROCESS)

**ğŸš¨ CRITICAL**: This is THE workflow for Sandbox testing. Do NOT use manual `adb`/`xcrun` commands to bypass it.

### The Required Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Update MainPage.xaml[.cs] with your test scenario       â”‚
â”‚    - Add UI elements for reproduction                       â”‚
â”‚    - Add AutomationIds to all interactive elements          â”‚
â”‚    - Add Console.WriteLine with "SANDBOX" markers           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Update Appium test to match your MainPage               â”‚
â”‚    CustomAgentLogsTmp/Sandbox/RunWithAppiumTest.cs         â”‚
â”‚    - Update element locators to match AutomationIds        â”‚
â”‚    - Add test logic (tap buttons, verify labels)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Run BuildAndRunSandbox.ps1                               â”‚
â”‚    pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform X  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Validate results using SYSTEMATIC CHECKLIST             â”‚
â”‚    - Step 1: Check for errors/exceptions                   â”‚
â”‚    - Step 2: Verify test actions (Tapping, etc.)           â”‚
â”‚    - Step 3: Verify "Test completed"                       â”‚
â”‚    - Step 4: Check device logs for SANDBOX markers         â”‚
â”‚    - Step 5-6: Screenshots and exit code                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. Did ALL validation checks pass?                         â”‚
â”‚    YES â†’ Report success with summary (go to step 8)        â”‚
â”‚    NO  â†’ Continue to step 6                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. Investigate failure from captured logs                  â”‚
â”‚    - Read CustomAgentLogsTmp/Sandbox/android-device.log    â”‚
â”‚    - Read CustomAgentLogsTmp/Sandbox/build-run-output.log  â”‚
â”‚    - Identify root cause (element not found? crash?)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 7. Fix the issue and LOOP BACK TO STEP 3                   â”‚
â”‚    - Update MainPage if UI/code issue                      â”‚
â”‚    - Update RunWithAppiumTest.cs if test issue             â”‚
â”‚    - Update both if AutomationId mismatch                  â”‚
â”‚    - Max 3 iterations before reporting as blocked          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 8. Report comprehensive summary to user                    â”‚
â”‚    - Test scenario source and justification                â”‚
â”‚    - Validation results                                    â”‚
â”‚    - Verdict (success/partial/issues/blocked)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âŒ What NOT To Do

**Never use manual commands during testing**:
- âŒ `adb logcat`, `adb shell`, `adb install`
- âŒ `xcrun simctl spawn`, `xcrun simctl install`
- âŒ `dotnet build`, `dotnet run`

**Why**: Script already captured everything. Manual commands show CURRENT state, not test execution state.

**âœ… Correct**: Edit files â†’ Rerun `BuildAndRunSandbox.ps1`

### âœ… Correct Iteration Example

**Most common case - Test fails to find element**:
```bash
# 1. Check what went wrong
grep "no such element" CustomAgentLogsTmp/Sandbox/build-run-output.log

# 2. Check what DOES exist in MainPage
grep AutomationId src/Controls/samples/Controls.Sample.Sandbox/MainPage.xaml

# 3. Fix MainPage: Add AutomationIds
# Edit MainPage.xaml: <Button AutomationId="NavigateButton" ...

# 4. Fix test: Update to match
# Edit RunWithAppiumTest.cs: App.WaitForElement("NavigateButton");

# 5. Rerun
pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform android
```

**When validation passes**: Report success with comprehensive summary

### When to Stop Iterating

- âœ… **All validation checks pass** â†’ Report success with detailed summary
- âŒ **Max 3 iterations reached** â†’ Report as blocked with all details from attempts
- âŒ **Build fails repeatedly** â†’ Report build issue with error details
- âŒ **Root cause unclear after log analysis** â†’ Ask for guidance with log excerpts
- âŒ **Issue appears to be PR bug, not test** â†’ Report findings to user

### Mental Model: The Script is Your Robot

BuildAndRunSandbox.ps1 handles: build â†’ deploy â†’ capture logs â†’ run test â†’ report

**Your workflow**: Edit files â†’ Run script â†’ Read logs â†’ Fix issues â†’ Repeat

---

## Output Format

Provide a concise test summary:

```markdown
## PR Testing Summary

**PR**: #XXXXX - [Title]
**Platform Tested**: Android/iOS
**Issue**: [Brief description]

---

### Test Scenario Setup

**ğŸš¨ REQUIRED - Source of Test Scenario**:
- **Source**: [From issue reproduction / From PR UITest / Custom scenario]
- **Why this source**: [e.g., "Issue #XXXXX provides detailed repro steps" / "PR includes UITest that demonstrates the fix" / "No repro available, created scenario based on PR code changes"]
- **Link to source**: [URL to issue comment with repro, or path to UITest file]

**What was tested**:
- [Specific actions taken - e.g., "Tap 'Toggle RTL' button, then tap 'Show Dialog' button"]
- [UI elements involved - e.g., "Button with AutomationId='ToggleButton', Dialog with Label"]
- [Expected behavior - e.g., "Dialog should appear with correct RTL padding on label"]

---

### Test Results WITH PR Fix

**Observed Behavior**:
- [What happened when running the test]
- [Appium test results]
- [Relevant log excerpts]

**Screenshots**: [Reference if taken, but not for validation]

---

### Verdict

âœ… **FIX VALIDATED** - Test scenario completes successfully, expected behavior observed
OR
âš ï¸ **PARTIAL** - Fix appears to work but [note any concerns]
OR
âŒ **ISSUES FOUND** - [Specific problems encountered]
OR
ğŸš« **CANNOT TEST** - [Build failures, setup issues, etc.]

---

### Notes for User
- Test scenario is set up in Sandbox and ready for manual verification if needed
- To verify bug reproduction without fix, revert PR changes: `git checkout main -- [fix files]`
- Then rerun: `pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform [android|ios]`
```

---

## Best Practices

1. **Use issue reproduction when available** - Most reliable test scenario
2. **Adapt PR's UITests if no repro** - They're already designed to test the fix
3. **Validate programmatically, reference visually** - Use Appium element queries for validation, screenshots only for additional context
4. **Use colored backgrounds** - Makes layout issues visible
5. **Add console markers** - Easy to grep logs  
6. **Test multiple iterations** - Race conditions need multiple runs (3-5 times)
7. **Leave Sandbox as-is** - User will iterate on it after your testing
8. **Document your test scenario thoroughly** - Include source (issue/UITest/custom), why you chose it, specific actions, and expected behavior so user can verify

**Screenshot Usage**:
- âœ… Take screenshots for **context and reference** (e.g., showing layout before/after)
- âœ… Include in report if they provide **additional insight** beyond what logs show
- âŒ Do NOT rely on screenshots as **primary validation** - use Appium element queries and log analysis
- âŒ Do NOT take screenshots just to show "it works" - validation should come from test assertions

---

## Log Capture and Review

### Where Logs Are Saved

After running BuildAndRunSandbox.ps1, all logs are in `CustomAgentLogsTmp/Sandbox/`:

1. **Android**: `CustomAgentLogsTmp/Sandbox/android-device.log`
2. **iOS**: `CustomAgentLogsTmp/Sandbox/ios-device.log`
3. **Appium**: `CustomAgentLogsTmp/Sandbox/appium.log`

### Viewing Logs

```bash
# View device logs
cat CustomAgentLogsTmp/Sandbox/android-device.log
# or
cat CustomAgentLogsTmp/Sandbox/ios-device.log

# Search for specific output
grep "TEST OUTPUT" CustomAgentLogsTmp/Sandbox/android-device.log

# View Appium logs
cat CustomAgentLogsTmp/Sandbox/appium.log
```

---

## ğŸš¨ ABSOLUTE RULE: BuildAndRunSandbox.ps1 is THE ONLY Deployment Method

**THIS IS MANDATORY. NOT A SUGGESTION.**

âŒ If typing `adb`/`xcrun` commands during testing â†’ STOP. You're violating the workflow.

**Why**: Manual commands show CURRENT state, not test execution state. Script already captured correct logs during test.

**âŒ NEVER during testing**: `adb logcat`, `adb install`, `adb shell`, `xcrun simctl install/spawn`, `dotnet build/run`

**âœ… ONLY exception**: Finding/booting specific iOS device BEFORE running script (`xcrun simctl list/boot`)

**Correct workflow**:
1. Edit files (MainPage, RunWithAppiumTest.cs)
2. Run: `pwsh .github/scripts/BuildAndRunSandbox.ps1 -Platform X`
3. Analyze logs in `CustomAgentLogsTmp/Sandbox/` (android-device.log, appium.log)
4. Fix issues, rerun script

**Expected logs**: `android-device.log` or `ios-device.log`, `appium.log`, `RunWithAppiumTest.cs`, optional screenshots

---

## Troubleshooting & Recovery

**Retry up to 3 times before reporting as blocked.** After each failure: analyze logs â†’ fix â†’ rerun script.

### Common Issues

| Issue | Recovery | Max Retries |
|-------|----------|-------------|
| Build error | Check SDK version, `dotnet tool restore` | 2 |
| App crash | Check stack trace in device log, fix code/XAML | 3 |
| Element not found | Verify AutomationIds match, check app loaded | 2 |
| Fast Deployment (Android) | Add `appium:noReset` capability | 1 |
| XAML parse error | Verify event handler exists in code-behind | 2 |

### Element Not Found Debugging

ğŸš¨ If Appium can't find initial element, app is NOT running correctly.

**Check**:
```bash
# Look for crashes
grep -i "FATAL\|crash\|exception" CustomAgentLogsTmp/Sandbox/android-device.log | tail -20

# Verify app launched
grep "SANDBOX.*MainPage" CustomAgentLogsTmp/Sandbox/android-device.log
```

**Root causes**: App crashed, XAML parse error, AutomationId mismatch, Android Fast Deployment

### When to Stop & Report
- âœ… **Continue**: Minor warnings, non-critical timeouts, platform differences
- âŒ **Stop**: Can't checkout PR, build fails after max retries, SDK mismatch, root cause unclear
**Action**: Try alternative approaches

1. Check linked issue for "Reproduction" section
2. Look for PR's UITest files in `TestCases.HostApp/Issues/`
3. Examine PR code changes to understand what's being fixed
4. Create minimal test scenario based on code analysis
5. Report to user if reproduction scenario is unclear

### Test Shows Unexpected Behavior
**Action**: Document and report

```markdown
âš ï¸ Unexpected behavior during testing

**What I expected**: [Based on issue description]

**What I observed**: [Actual behavior]

**Test scenario**: [What was tested]

**Logs**: [Relevant excerpts]

**Question for user**: Is this expected behavior, or does this indicate an issue?
```

---

## Common Mistakes to Avoid

- âŒ Using TestCases.HostApp for manual PR validation (use Sandbox)
- âŒ Manual build/deploy commands instead of BuildAndRunSandbox.ps1
- âŒ Testing only one platform when PR affects multiple
- âŒ Using screenshots for validation (use Appium element queries)
- âŒ Creating test scenario without checking issue for reproduction steps
- âŒ Ignoring PR's existing UITests when available
- âŒ Cleaning up or reverting Sandbox changes (user will iterate on it)

**Testing Tips**:
- For layout bugs: Use `element.GetRect()` to measure positions
- For SafeArea PRs: Measure child content position, not parent size
- Add `Console.WriteLine("SANDBOX ...")` markers for debugging

---

## Appendix: Cleanup (Only When User Requests)

âš ï¸ **DO NOT clean up after testing** - Leave Sandbox as-is so user can iterate on it.

Only use these commands if the **user explicitly requests cleanup**:

### Sandbox App Cleanup (User Request Only)
```bash
# Revert all changes to Sandbox app
git checkout -- src/Controls/samples/Controls.Sample.Sandbox/
```

### Sandbox Test Files Cleanup (User Request Only)
```bash
# Remove Appium test directory (gitignored)
rm -rf CustomAgentLogsTmp/Sandbox/
```
