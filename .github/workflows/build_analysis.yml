name: "Build Analysis"

on:
  check_run:
    types: [completed]
  check_suite:
    types: [completed]

jobs:
  analyze-build:
    name: Analyze Build
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      models: read
  
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Print GitHub Context
        env:
          GITHUB_CONTEXT: ${{ toJSON(github) }}
        run: |
          echo "GitHub Context: $GITHUB_CONTEXT"

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '9.0.x'

      - name: Fetch check results
        if: ${{ github.event_name == 'check_run' || github.event_name == 'check_suite' }}
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          set -euo pipefail
          # Ensure jq for nicer log extraction
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y jq
          fi
          chmod +x eng/scripts/get-check-results.sh
          if [ "${{ github.event_name }}" = "check_run" ]; then
            eng/scripts/get-check-results.sh --check-run-id "${{ github.event.check_run.id }}"
            RID="${{ github.event.check_run.id }}"
            if [ -f "logs/check-run-${RID}.log" ]; then
              echo "================ Check Run ${RID} Output ================"
              sed -n '1,2000p' "logs/check-run-${RID}.log"
            elif [ -f "logs/check-run-${RID}.json" ]; then
              echo "================ Check Run ${RID} (Parsed from JSON) ================"
              if command -v jq >/dev/null 2>&1; then
                jq -r '"Summary:\n" + (.output.summary // "") + "\n\nOutput:\n" + (.output.text // "")' "logs/check-run-${RID}.json"
              else
                head -c 50000 "logs/check-run-${RID}.json" | cat
              fi
            else
              echo "No logs found for check run ${RID}"
            fi
          else
            eng/scripts/get-check-results.sh --check-suite-id "${{ github.event.check_suite.id }}"
            SID="${{ github.event.check_suite.id }}"
            echo "================ Check Suite ${SID} Outputs ================"
            count=0
            for f in logs/check-run-*.log; do
              if [ -f "$f" ]; then
                echo "------------- $(basename "$f") -------------"
                sed -n '1,2000p' "$f"
                echo
                count=$((count+1))
              fi
            done
            if [ "$count" -eq 0 ]; then
              echo "No per-run .log files found. Suite listing:"
              if [ -f "logs/check-suite-${SID}.json" ] && command -v jq >/dev/null 2>&1; then
                jq -r '.check_runs[] | "\(.id) - \(.name): status=\(.status), conclusion=\(.conclusion)"' "logs/check-suite-${SID}.json"
              elif [ -f "logs/check-suite-${SID}.json" ]; then
                head -c 50000 "logs/check-suite-${SID}.json" | cat
              else
                echo "No suite JSON found at logs/check-suite-${SID}.json"
              fi
            fi
          fi

      - name: Fetch Azure DevOps logs (if linked)
        if: ${{ github.event_name == 'check_run' }}
        shell: bash
        run: |
          set -euo pipefail
          # Export secret (may be empty if not configured)
          export AZURE_DEVOPS_TOKEN="${{ secrets.AZURE_DEVOPS_TOKEN }}"
          RID="${{ github.event.check_run.id }}"
          JSON_PATH="logs/check-run-${RID}.json"
          if [ -f "$JSON_PATH" ]; then
            chmod +x eng/scripts/get-azure-devops-logs.sh || true
            if [ -n "${AZURE_DEVOPS_TOKEN:-}" ]; then
              echo "Attempting to fetch Azure DevOps logs from $JSON_PATH"
              eng/scripts/get-azure-devops-logs.sh --check-run-json "$JSON_PATH" --output-dir logs || echo "Skipping ADO logs (no link or fetch failed)"
            else
              echo "AZURE_DEVOPS_TOKEN not set; skipping Azure DevOps logs fetch."
            fi
          else
            echo "Check run JSON not found at $JSON_PATH; cannot derive ADO link."
          fi

      - name: Select log file to analyze
        if: ${{ github.event_name == 'check_run' && github.event.check_run.conclusion != 'success' }}
        id: picklog
        shell: bash
        run: |
          set -euo pipefail
          RID="${{ github.event.check_run.id }}"
          LOG_PATH=""
          if compgen -G "logs/azure-devops/*/combined.log" > /dev/null; then
            LOG_PATH=$(ls -1t logs/azure-devops/*/combined.log | head -n1)
          elif [ -f "logs/check-run-${RID}.log" ]; then
            LOG_PATH="logs/check-run-${RID}.log"
          elif [ -f "logs/check-run-${RID}.json" ]; then
            if ! command -v jq >/dev/null 2>&1; then
              sudo apt-get update -y
              sudo apt-get install -y jq
            fi
            jq -r '"Summary:\n" + (.output.summary // "") + "\n\nOutput:\n" + (.output.text // "")' "logs/check-run-${RID}.json" > "logs/synth-${RID}.log" || true
            if [ -s "logs/synth-${RID}.log" ]; then LOG_PATH="logs/synth-${RID}.log"; fi
          fi
          if [ -z "$LOG_PATH" ]; then
            mkdir -p logs
            : > logs/empty.log
            LOG_PATH="logs/empty.log"
          fi
          echo "path=$LOG_PATH" >> "$GITHUB_OUTPUT"
          echo "Selected log: $LOG_PATH"

      - name: Reduce log for AI (focus errors)
        if: ${{ github.event_name == 'check_run' && github.event.check_run.conclusion != 'success' }}
        id: reducelog
        shell: bash
        run: |
          set -euo pipefail
          IN="${{ steps.picklog.outputs.path }}"
          OUT="logs/reduced-for-ai.log"
          mkdir -p logs
          # If very small already, just link it
          size=$(wc -c < "$IN" | tr -d ' ')
          if [ "${size:-0}" -lt 50000 ]; then
            cp "$IN" "$OUT"
            echo "path=$OUT" >> "$GITHUB_OUTPUT"
            echo "Log is small; using as-is at $OUT"
            exit 0
          fi

          # Build combined regex from patterns file (one per line)
          PATTERNS_FILE=".github/patterns/build-failure-patterns.txt"
          if [ ! -f "$PATTERNS_FILE" ]; then
            echo "Patterns file not found at $PATTERNS_FILE" >&2
            # Fallback to a minimal default
            COMBINED='Build FAILED|MSBUILD : error|^##\[error\]|##vso\[task\.logissue type=error'
          else
            # Join non-empty, non-comment lines with |
            COMBINED=$(grep -vE '^\s*(#|$)' "$PATTERNS_FILE" | awk 'BEGIN{ORS="|"} {gsub(/\r/,"",$0); printf "%s", $0}' | sed 's/|$//')
            if [ -z "${COMBINED}" ]; then
              COMBINED='Build FAILED|MSBUILD : error|^##\[error\]|##vso\[task\.logissue type=error'
            fi
          fi

          # Collect line numbers around likely error markers
          tmpidx="$(mktemp)" || tmpidx="/tmp/reduce.$$"
          # Use patterns from the patterns file
          grep -nEi "${COMBINED}" "$IN" | cut -d: -f1 > "$tmpidx" || true
          # Build a set of line ranges +/- 30 lines
          tmpadr="$(mktemp)" || tmpadr="/tmp/ranges.$$"
          while IFS= read -r ln; do
            [ -z "$ln" ] && continue
            start=$(( ln-30 )); [ $start -lt 1 ] && start=1
            stop=$(( ln+30 ))
            echo "$start,$stop" >> "$tmpadr"
          done < "$tmpidx"
          # Always include the tail of the file (last 400 lines)
          total_lines=$(wc -l < "$IN" | tr -d ' ')
          if [ "${total_lines:-0}" -gt 0 ]; then
            tail_start=$(( total_lines-400 )); [ $tail_start -lt 1 ] && tail_start=1
            echo "$tail_start,$total_lines" >> "$tmpadr"
          fi
          # Merge overlapping ranges
          awk -F, 'BEGIN{OFS=","} {s=$1; e=$2; if (NR==1){ps=s; pe=e; next} if (s<=pe+1){ if (e>pe) pe=e } else { print ps,pe; ps=s; pe=e } } END{ if (NR>0) print ps,pe }' <(sort -n -t, -k1,1 -k2,2 "$tmpadr") > "$tmpadr.merged"
          # Extract lines
          : > "$OUT"
          while IFS=, read -r s e; do
            echo "================ Range ${s}-${e} ================" >> "$OUT"
            sed -n "${s},${e}p" "$IN" >> "$OUT"
            echo >> "$OUT"
          done < "$tmpadr.merged"
          # Deduplicate consecutive duplicate lines to reduce noise
          awk 'NR==1{print; prev=$0; next} {if ($0!=prev) print; prev=$0}' "$OUT" > "$OUT.tmp" && mv "$OUT.tmp" "$OUT"
          echo "path=$OUT" >> "$GITHUB_OUTPUT"
          echo "Reduced log written to $OUT"

      - name: Sanitize log for prompt
        if: ${{ github.event_name == 'check_run' && github.event.check_run.conclusion != 'success' }}
        id: sanitizelog
        shell: bash
        run: |
          set -euo pipefail
          IN="${{ steps.reducelog.outputs.path }}"
          mkdir -p logs
          RAW_OUT="logs/sanitized-for-prompt.log"
          # Remove CR, ANSI escapes, and non-printable characters except TAB/NEWLINE
          perl -pe 's/\r//g; s/\x1B\[[0-?]*[ -\/]*[@-~]//g; s/[^[:print:]\t\n]//g' "$IN" > "$RAW_OUT"
          # Cap to 100k bytes to keep prompt size reasonable
          OUT="logs/sanitized-for-prompt.head"
          head -c 60000 "$RAW_OUT" > "$OUT" || true
          echo "path=$OUT" >> "$GITHUB_OUTPUT"
          echo "Sanitized log written to $OUT"

      - name: Indent log for prompt YAML
        if: ${{ github.event_name == 'check_run' && github.event.check_run.conclusion != 'success' }}
        id: indentlog
        shell: bash
        run: |
          set -euo pipefail
          IN="${{ steps.sanitizelog.outputs.path }}"
          OUT="logs/indented-for-prompt.log"
          mkdir -p logs
          # Prefix each line with six spaces to safely embed in YAML block scalar
          sed 's/^/      /' "$IN" > "$OUT"
          echo "path=$OUT" >> "$GITHUB_OUTPUT"
          echo "Indented log written to $OUT"

      - name: AI analyze failure (GitHub Models)
        if: ${{ github.event_name == 'check_run' && github.event.check_run.conclusion != 'success' }}
        id: inference
        uses: actions/ai-inference@v1
        with:
          token: ${{ github.token }}
          model: openai/gpt-5
          prompt-file: .github/prompts/build-analysis.prompt.yml
          # max-tokens: 800
          input: |
            name: ${{ github.event.check_run.name }}
            url: ${{ github.event.check_run.details_url }}
            conclusion: ${{ github.event.check_run.conclusion }}
          file_input: |
            log_indented: ${{ steps.indentlog.outputs.path }}

      - name: Find PR for commit
        if: ${{ github.event_name == 'check_run' && github.event.check_run.conclusion != 'success' }}
        id: findpr
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          set -euo pipefail
          OWNER="${GITHUB_REPOSITORY%%/*}"; REPO="${GITHUB_REPOSITORY##*/}"
          SHA="${{ github.event.check_run.head_sha }}"
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y jq
          fi
          prs=$(curl -sS -H "Authorization: Bearer ${GITHUB_TOKEN}" -H "Accept: application/vnd.github+json" "https://api.github.com/repos/$OWNER/$REPO/commits/$SHA/pulls")
          prnum=$(echo "$prs" | jq -r '.[0].number // empty')
          if [ -n "$prnum" ]; then
            echo "pr=$prnum" >> "$GITHUB_OUTPUT"
            echo "Found PR #$prnum for commit $SHA"
          else
            echo "No PR found for commit $SHA"
          fi

      - name: Post AI analysis PR comment
        if: ${{ github.event_name == 'check_run' && github.event.check_run.conclusion != 'success' && steps.findpr.outputs.pr != '' }}
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          set -euo pipefail
          RID="${{ github.event.check_run.id }}"
          SHA="${{ github.event.check_run.head_sha }}"
          NAME="${{ github.event.check_run.name }}"
          DETAILS_URL="${{ github.event.check_run.details_url }}"
          ANALYSIS='${{ steps.inference.outputs.response }}'
          PRNUM='${{ steps.findpr.outputs.pr }}'

          if [ -z "$ANALYSIS" ]; then
            echo "No AI response; skipping PR comment."
            exit 0
          fi

          SHOULD=$(echo "$ANALYSIS" | jq -r '.shouldRequeue' 2>/dev/null || echo "")
          SHORT=$(echo "$ANALYSIS" | jq -r '.shortSummary' 2>/dev/null || echo "")
          DECISION=""; if [ "$SHOULD" = "true" ]; then DECISION="YES"; elif [ "$SHOULD" = "false" ]; then DECISION="NO"; fi
          {
            echo "# ðŸ¤– Build analysis for check \`$NAME\` (ID $RID)"
            echo
            echo "- Details: [$DETAILS_URL]($DETAILS_URL)"
            echo "- Commit: \`$SHA\`"
            if [ -n "$DECISION" ]; then echo "- Should requeue: **$DECISION**"; fi
            if [ -n "$SHORT" ] && [ "$SHORT" != "null" ]; then echo "- Why: $SHORT"; fi
            echo
            echo "<details><summary>AI decision</summary>"
            echo
            echo '```json'
            echo "$ANALYSIS"
            echo '```'
            echo
            echo "</details>"
          } > analysis_comment.md

          OWNER="${GITHUB_REPOSITORY%%/*}"; REPO="${GITHUB_REPOSITORY##*/}"
          BODY_JSON=$(jq -n --rawfile body analysis_comment.md '{body:$body}')
          curl -sS -H "Authorization: Bearer ${GITHUB_TOKEN}" -H "Accept: application/vnd.github+json" -X POST -d "$BODY_JSON" "https://api.github.com/repos/$OWNER/$REPO/issues/$PRNUM/comments" >/dev/null
          echo "Posted AI analysis comment to PR #$PRNUM"

      - name: Log AI analysis (no PR)
        if: ${{ github.event_name == 'check_run' && github.event.check_run.conclusion != 'success' && steps.findpr.outputs.pr == '' }}
        shell: bash
        run: |
          set -euo pipefail
          ANALYSIS='${{ steps.inference.outputs.response }}'
          echo "AI analysis (no PR found):"
          echo "$ANALYSIS"

      - name: Upload check result logs artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: check-results-${{ github.run_id }}
          path: |
            logs/**
          if-no-files-found: ignore
          retention-days: 7
      